{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b18a4711-1e0e-4548-8ca6-e49dafd08f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "420c73c7-e7af-4f90-b9e4-7b6bb01ca190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\son.nguyenngoctruong\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\son.nguyenngoctruong\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\son.nguyenngoctruong\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\users\\son.nguyenngoctruong\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\son.nguyenngoctruong\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\son.nguyenngoctruong\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b38cc9c0-d12f-4b3c-a775-d1e10c7e49dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\son.nguyenngoctruong\\AppData\\Roaming\\nltk_dat\n",
      "[nltk_data]     a...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8edaf974-558b-4288-aa79-5a501cccb937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "940f25a5-75e3-4c7d-9d07-5c1c909307e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RevId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Comment</th>\n",
       "      <th>image_urls</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3839333</td>\n",
       "      <td>10106093.0</td>\n",
       "      <td>X√¥i d·∫ªo, ƒë·ªì ƒÉn ƒë·∫≠m v·ªã. H·ªôp x√¥i ƒë∆∞·ª£c l√≥t l√° tr√¥...</td>\n",
       "      <td>['https://images.foody.vn/res/g97/966781/s800/...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2824877</td>\n",
       "      <td>786914.0</td>\n",
       "      <td>G·ªçi ship 1 xu·∫•t cari g√† b√°nh naan v√† 3 mi·∫øng g...</td>\n",
       "      <td>['https://images.foody.vn/res/g69/688413/s800/...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9816702</td>\n",
       "      <td>22467889.0</td>\n",
       "      <td>Th·ªùi ti·∫øt l·∫°nh nh∆∞ n√†y, c·∫£ nh√† r·ªß nhau ƒë·∫øn leg...</td>\n",
       "      <td>['https://images.foody.vn/res/g72/715078/s800/...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2684585</td>\n",
       "      <td>1889449.0</td>\n",
       "      <td>Em c√≥ ƒë·ªçc review th·∫•y mng b·∫£o tr√† s·ªØa n∆∞·ªõng ƒë·ªÅ...</td>\n",
       "      <td>['https://images.foody.vn/res/g90/895545/s800/...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2737987</td>\n",
       "      <td>8839942.0</td>\n",
       "      <td>ƒê·ªì ƒÉn r·∫•t ngon, nh√† h√†ng c≈©ng r·∫•t ƒë·∫πp, t·∫•t c·∫£ ...</td>\n",
       "      <td>['https://images.foody.vn/res/g4/30186/s800/fo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0    RevId      UserId  \\\n",
       "0          0  3839333  10106093.0   \n",
       "1          1  2824877    786914.0   \n",
       "2          2  9816702  22467889.0   \n",
       "3          3  2684585   1889449.0   \n",
       "4          4  2737987   8839942.0   \n",
       "\n",
       "                                             Comment  \\\n",
       "0  X√¥i d·∫ªo, ƒë·ªì ƒÉn ƒë·∫≠m v·ªã. H·ªôp x√¥i ƒë∆∞·ª£c l√≥t l√° tr√¥...   \n",
       "1  G·ªçi ship 1 xu·∫•t cari g√† b√°nh naan v√† 3 mi·∫øng g...   \n",
       "2  Th·ªùi ti·∫øt l·∫°nh nh∆∞ n√†y, c·∫£ nh√† r·ªß nhau ƒë·∫øn leg...   \n",
       "3  Em c√≥ ƒë·ªçc review th·∫•y mng b·∫£o tr√† s·ªØa n∆∞·ªõng ƒë·ªÅ...   \n",
       "4  ƒê·ªì ƒÉn r·∫•t ngon, nh√† h√†ng c≈©ng r·∫•t ƒë·∫πp, t·∫•t c·∫£ ...   \n",
       "\n",
       "                                          image_urls  Rating  \n",
       "0  ['https://images.foody.vn/res/g97/966781/s800/...     1.0  \n",
       "1  ['https://images.foody.vn/res/g69/688413/s800/...     0.0  \n",
       "2  ['https://images.foody.vn/res/g72/715078/s800/...     1.0  \n",
       "3  ['https://images.foody.vn/res/g90/895545/s800/...     0.0  \n",
       "4  ['https://images.foody.vn/res/g4/30186/s800/fo...     1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_csv = './input/full_train.csv'\n",
    "df = pd.read_csv(base_csv)\n",
    "df = df[df.Comment == df.Comment]\n",
    "df = df[df.Rating == df.Rating]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "247509ac-9fb1-4ab3-bc05-de104c592c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X√¥i d·∫ªo, ƒë·ªì ƒÉn ƒë·∫≠m v·ªã. H·ªôp x√¥i ƒë∆∞·ª£c l√≥t l√° tr√¥ng r·∫•t th√≠ch'\n",
      " 'G·ªçi ship 1 xu·∫•t cari g√† b√°nh naan v√† 3 mi·∫øng g√† n∆∞·ªõng(ƒë∆∞·ª£c t·∫∑ng 1 coca). ƒê·ªì ƒÉn kh√° ngon, t·ªïng 210k ƒë∆∞·ª£c gi·∫£m 50k c√≤n 160k. Tuy nhi√™n g·ªçi 3 mi·∫øng g√† th√¨ thi·∫øu 1 mi·∫øng, m√† k·ªÉ c·∫£ ƒë√≥ ƒë·ªß ba mi·∫øng th√¨ kh·∫©u ph·∫ßn v·∫´n l√† qu√° √≠t so v·ªõi gi√° 120k 1 su·∫•t.'\n",
      " 'Th·ªùi ti·∫øt l·∫°nh nh∆∞ n√†y, c·∫£ nh√† r·ªß nhau ƒë·∫øn legarden th√¨ h·∫øt √Ω. Nh√† m√¨nh ƒë√£ ƒÉn ·ªü ƒë√¢y nhi·ªÅu r·ªìi r·∫•t ∆∞ng th√°i ƒë·ªô ph·ª•c v·ª• c·ªßa c√°c b·∫°n nh√¢n vi√™n, t·∫≠n t√¨nh nh∆∞ ng∆∞·ªùi nh√†. ƒê·ªì ƒÉn th√¨ mi·ªÖn b√†n m√¨nh ch∆∞a t√¨m ƒë∆∞·ª£c qu√°n ƒÉn h·ªìng kong n√†o chu·∫©n v·ªã nh∆∞ ·ªü ƒë√¢y'\n",
      " ...\n",
      " 'Ngay t·ª´ l√∫c ƒë·∫ßu ti√™n b∆∞·ªõc v√†o nh√† h√†ng ƒë√£ ƒë∆∞·ª£c nh√¢n vi√™n ƒë√≥n ti·∫øp r·∫•t nhi·ªát t√¨nh. R·∫•t ·∫•n t∆∞·ª£ng v·ªõi c√°ch chƒÉm s√≥c kh√°ch h√†ng c·ªßa nh√¢n vi√™n ·ªü ƒë√¢y. Lu√¥n nhi·ªát t√¨nh v√† √¢n c·∫ßn v·ªõi kh√°ch h√†ng. Nh√† h√†ng c≈©ng ƒë∆∞·ª£c trang tr√≠ r·∫•t ƒë·∫πp m·∫Øt. Ch·∫Øc ch·∫Øn s·∫Ω quay l·∫°i. V√† s·∫Ω gi·ªõi thi·ªáu b·∫°n b√® t·ªõi ƒë√¢y.'\n",
      " 'ƒê·∫∑t ƒÉn th·ª≠ m√† th·∫•y ng√≥n c√°...! ü§© s·∫Ω c√≤n ·ªßn h·ªô qu√°n nh√¨u nh√¨u.'\n",
      " 'Nay xem b√≥ng ƒë√° VN l∆∞·ªùi n·∫•u c∆°m. Nghe c√°c b·∫°n gi·ªõi thi·ªáu m·ª≥ √Ω ch·ªó n√†y si√™u ngon, gi√° l·∫°i m·ªÅm üòãüòãƒê·∫∑t th·ª≠ v·ªÅ xem th·∫ø n√†o. \\n\\nM√¨nh ch·ªçn combo m·ª≥ v√† cam √©püòçüòçC·∫£ order v√† ship si√™u nhanh 30p l√† ƒë·∫øn r·ªìiüòçüòç\\nV·ªÅ ngo·∫°i h√¨nh m√¨nh th·∫•y b√¨nh th∆∞·ªùng. Nh∆∞ng m√† ng·ªìi x√∫c lu√¥n cho n√≥ngüòÇüòÇS·ªët th∆°m, v·ª´a v·ªã, c·∫£m th·∫•y th·ªãt b√≤ everywhereüòãüòãM·ª≥ m√¨nh th·∫•y ok. ƒÇn xong l√†m c·ªëc n∆∞·ªõc √©p cam no cƒÉng. \\n59k c·∫£ ship qu√° ok.\\nƒÇn xong v·∫´n c√≤n th√®müòãüòã\\n>>S·∫Ω ·ªßng h·ªô d√†i d√†i üòâ. \\nGi·ªù th√¨ Vi·ªát Nam chi·∫øn th·∫Øng th√¥iii üáªüá≥üáªüá≥üáªüá≥üèÜüèÜüèÜ'] [1. 0. 1. ... 1. 1. 1.]\n",
      "shape of train data is (6802,)\n",
      "shape of test data is (2268,)\n"
     ]
    }
   ],
   "source": [
    "X,y = df['Comment'].values,df['Rating'].values\n",
    "print(X, y)\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y)\n",
    "print(f'shape of train data is {x_train.shape}')\n",
    "print(f'shape of test data is {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbcf7d2e-e26e-4cdf-a291-b5e554a91d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd = pd.Series(y_train).value_counts()\n",
    "sns.barplot(x=np.array([1.0,0.0]),y=dd.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7285c380-576b-4a14-8570-970b61d6f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(s):\n",
    "    # Remove all non-word characters (everything except numbers and letters)\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "    # Replace all runs of whitespaces with no space\n",
    "    s = re.sub(r\"\\s+\", '', s)\n",
    "    # replace digits with no space\n",
    "    s = re.sub(r\"\\d\", '', s)\n",
    "\n",
    "    return s\n",
    "\n",
    "def tockenize(x_train,y_train,x_val,y_val):\n",
    "    word_list = []\n",
    "\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    for sent in x_train:\n",
    "        for word in sent.lower().split():\n",
    "            word = preprocess_string(word)\n",
    "            if word not in stop_words and word != '':\n",
    "                word_list.append(word)\n",
    "  \n",
    "    corpus = Counter(word_list)\n",
    "    # sorting on the basis of most common words\n",
    "    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\n",
    "    # creating a dict\n",
    "    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n",
    "    \n",
    "    # tockenize\n",
    "    final_list_train,final_list_test = [],[]\n",
    "    for sent in x_train:\n",
    "            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
    "                                     if preprocess_string(word) in onehot_dict.keys()])\n",
    "    for sent in x_val:\n",
    "            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
    "                                    if preprocess_string(word) in onehot_dict.keys()])\n",
    "            \n",
    "    encoded_train = [1 if label =='positive' else 0 for label in y_train]  \n",
    "    encoded_test = [1 if label =='positive' else 0 for label in y_val] \n",
    "    return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86757bf4-6756-4b50-8ea4-f0b89986d976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([14, 19, 3, 65, 13, 82, 188, 84, 329, 778, 489, 177, 3, 24, 193, 8, 99, 30, 3, 335, 35, 549, 344, 393, 15, 110, 57, 35, 549, 344, 393, 12, 3, 99, 54, 728, 604, 13, 333, 327, 97, 107, 17, 1, 2, 427, 23, 4, 196, 3, 136, 311, 205, 132, 477, 54, 221, 17, 70, 590, 33, 537, 790, 28, 2, 12, 377, 393, 4, 173, 404, 267, 14, 19, 39, 3, 36, 359, 215, 378, 13, 4, 9, 59, 117, 791, 64, 1, 62, 11, 73, 813, 58, 90, 62, 11, 61, 83, 54, 1, 150, 103, 911, 199, 398, 374, 23, 32, 8, 35, 305, 63, 669, 669, 160, 388, 10, 244, 758, 20, 188, 84, 10, 7, 110, 48, 192, 197, 173, 404, 236, 232, 187, 235, 38, 47, 396, 300, 20, 112, 93, 37, 651, 721, 84, 112, 249, 759, 3, 580, 62, 57, 153, 2, 37, 16, 187, 235, 200, 34, 53, 57, 115, 16, 29, 32, 406, 1, 102, 133, 52, 98, 446, 651, 126, 102, 37, 183, 38, 47, 7, 538, 80, 15, 10, 62, 28, 100])\n",
      " list([41, 201, 37, 3, 84, 118, 186, 679, 15, 4, 679, 452, 215, 384, 4, 215, 808, 679, 12, 148, 21, 24, 679, 325, 268, 428, 15, 123, 408, 4, 28, 41, 58, 491, 279, 12, 28, 372, 286, 826, 104, 7, 17, 1, 28, 491, 63, 96, 165, 104, 166, 7, 104, 679, 101, 164, 818, 104, 166, 8, 166, 289, 35, 45, 3, 161, 148, 166, 2, 348, 73, 58, 1, 28, 26, 17, 1, 170, 37, 42, 60, 165, 104, 679, 101, 130, 1, 15, 41, 201, 306, 8, 155, 24, 70])\n",
      " list([819, 18, 9, 24, 249, 478, 135, 604, 53, 245, 46, 2, 135, 172, 11, 27, 819, 60, 8, 35, 263, 363, 100, 3, 41, 375, 7, 502, 178, 396, 3, 136, 307, 137, 5, 137, 143, 467, 51, 168, 126, 102, 62, 133, 5, 9, 14, 278, 386, 28, 2, 68])\n",
      " ...\n",
      " list([5, 30, 97, 107, 10, 22, 15, 23, 798, 21, 10, 167, 156, 170, 37, 175, 51, 16, 204, 133, 275, 229, 357, 22, 164, 798, 10, 34, 1, 171, 207, 204, 37, 127, 940, 39, 66, 36, 1, 798, 20, 62, 253, 179, 36, 146, 100, 105, 231, 9, 600, 340, 1, 337, 337, 16, 6, 414, 39, 8, 40, 52, 12, 74, 231])\n",
      " list([730, 599, 209, 34, 176, 36, 84, 9, 31, 66, 1, 176, 127, 121, 25, 160, 513, 205, 9, 329, 298, 96, 25, 48, 124, 891, 855, 7, 67, 202, 420, 315, 7, 286, 330, 67, 485, 218, 16, 934, 4, 92, 67, 485, 607, 189, 126, 102, 31, 28, 2, 763, 92, 7, 438, 2, 221, 20, 36, 98, 10, 18, 622, 4, 274, 55, 549, 72, 8, 33, 77, 710, 15, 37, 267, 17, 1, 90, 39, 182, 127, 442, 428, 575, 588, 286, 330, 39, 127, 28, 58, 286, 826, 282, 428, 508, 723, 16, 39, 26, 330, 189, 443, 25, 10, 13, 9, 32, 403, 55, 29, 115, 310, 32, 298, 23, 39, 3, 11, 28, 32, 403, 4, 23, 372, 171, 83, 250, 94, 332, 33, 309, 291, 28, 334])\n",
      " list([])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\son.nguyenngoctruong\\AppData\\Local\\Temp\\ipykernel_36080\\4123152163.py:38: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test,vocab = tockenize(x_train,y_train,x_test,y_test)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8fe7717-ba4f-4d15-b38e-1f0141d27efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of vocabulary is {len(vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "560e873d-b0a1-4a3d-be45-83c0bece9a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    6802.000000\n",
       "mean       75.078653\n",
       "std        66.349186\n",
       "min         0.000000\n",
       "25%        28.000000\n",
       "50%        58.000000\n",
       "75%       101.000000\n",
       "max       666.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_len = [len(i) for i in x_train]\n",
    "pd.Series(rev_len).hist()\n",
    "plt.show()\n",
    "pd.Series(rev_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b279a8be-0fca-41a6-b296-90d9930f051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_(sentences, seq_len):\n",
    "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
    "    for ii, review in enumerate(sentences):\n",
    "        if len(review) != 0:\n",
    "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27a11a67-eb69-425e-bfc8-af37175157fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...  62  28 100]\n",
      " [  0   0   0 ... 155  24  70]\n",
      " [  0   0   0 ...  28   2  68]\n",
      " ...\n",
      " [  0   0   0 ...  12  74 231]\n",
      " [  0   0   0 ... 291  28 334]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "===\n",
      "[[  0   0   0 ...  39  35  26]\n",
      " [  0   0   0 ...  69 227  11]\n",
      " [  0   0   0 ... 183  10 365]\n",
      " ...\n",
      " [  0   0   0 ... 265  63  68]\n",
      " [  0   0   0 ... 526 140  33]\n",
      " [  0   0   0 ... 658 309 291]]\n"
     ]
    }
   ],
   "source": [
    "#we have very less number of reviews with length > 500.\n",
    "#So we will consideronly those below it.\n",
    "x_train_pad = padding_(x_train,500)\n",
    "x_test_pad = padding_(x_test,500)\n",
    "print(x_train_pad)\n",
    "print('===')\n",
    "print(x_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98678aa0-73dc-401b-8d3e-b0d97593762d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x0000027CD06C4F40>\n"
     ]
    }
   ],
   "source": [
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "\n",
    "# make sure to SHUFFLE your data\n",
    "print(train_data)\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "from torch.autograd import Variable\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "# for i, (inputs, targets) in enumerate(train_loader):\n",
    "#     with torch.no_grad():\n",
    "#         inputs = Variable(inputs)\n",
    "#         targets = Variable(targets)\n",
    "#         print(\"targets.data\", targets)\n",
    "#         print(\"inputs.data\", inputs)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5703db45-0402-44d3-a0a0-07255ca7b0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x0000027CD06C4EE0>\n",
      "<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x0000027CD044FB20>\n",
      "Sample input size:  torch.Size([50, 500])\n",
      "Sample input: \n",
      " tensor([[  0,   0,   0,  ..., 274,  55, 334],\n",
      "        [  0,   0,   0,  ...,  36, 302, 100],\n",
      "        [  0,   0,   0,  ...,  27,  89,  55],\n",
      "        ...,\n",
      "        [  0,   0,   0,  ...,   4, 995,  53],\n",
      "        [  0,   0,   0,  ..., 455, 275,  78],\n",
      "        [  0,   0,   0,  ..., 121,  13,   9]], dtype=torch.int32)\n",
      "Sample input: \n",
      " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "print(train_loader)\n",
    "dataiter = iter(train_loader)\n",
    "print(dataiter)\n",
    "# sample_x, sample_y = dataiter.next()\n",
    "sample_x, sample_y = next(dataiter)\n",
    "\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print('Sample input: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "781ac31c-bac6-4446-a836-ae42a7b20789",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5):\n",
    "        super(SentimentRNN,self).__init__()\n",
    " \n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    " \n",
    "        self.no_layers = no_layers\n",
    "        self.vocab_size = vocab_size\n",
    "    \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        #lstm\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
    "                           num_layers=no_layers, batch_first=True)\n",
    "        \n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "        # linear and sigmoid layer\n",
    "        self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x,hidden):\n",
    "        batch_size = x.size(0)\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n",
    "        #print(embeds.shape)  #[50, 500, 1000]\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        \n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \n",
    "        \n",
    "        # dropout and fully connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "        \n",
    "        \n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
    "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
    "        hidden = (h0,c0)\n",
    "        return hidden\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2dab7644-5b69-4b15-8409-4b628230826f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n",
      "SentimentRNN(\n",
      "  (embedding): Embedding(1001, 64)\n",
      "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "no_layers = 2\n",
    "vocab_size = len(vocab) + 1 #extra 1 for padding\n",
    "print(vocab_size)\n",
    "embedding_dim = 64\n",
    "output_dim = 1\n",
    "hidden_dim = 256\n",
    "\n",
    "\n",
    "model = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5)\n",
    "\n",
    "#moving to gpu\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39e8dc21-7471-49e5-8f18-0a8807d632af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# function to predict accuracy\n",
    "def acc(pred,label):\n",
    "    pred = torch.round(pred.squeeze())\n",
    "    return torch.sum(pred == label.squeeze()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1ee42b3-4b3b-497f-a077-59874fae6551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n",
      "jjj===\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (2, 2, 256), got [2, 50, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36080\\1137639684.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# calculate the loss and perform backprop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36080\\4238004862.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0membeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# shape: B x S x Feature   since batch = True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m#print(embeds.shape)  #[50, 500, 1000]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mlstm_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    770\u001b[0m             \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 772\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    773\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    696\u001b[0m                            ):\n\u001b[0;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 698\u001b[1;33m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[0m\u001b[0;32m    699\u001b[0m                                'Expected hidden[0] size {}, got {}')\n\u001b[0;32m    700\u001b[0m         self.check_hidden_size(hidden[1], self.get_expected_cell_size(input, batch_sizes),\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[1;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[0;32m    229\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[0;32m    230\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected hidden[0] size (2, 2, 256), got [2, 50, 256]"
     ]
    }
   ],
   "source": [
    "clip = 5\n",
    "epochs = 5 \n",
    "valid_loss_min = np.Inf\n",
    "# train for some number of epochs\n",
    "epoch_tr_loss,epoch_vl_loss = [],[]\n",
    "epoch_tr_acc,epoch_vl_acc = [],[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    train_acc = 0.0\n",
    "    model.train()\n",
    "    # initialize hidden state \n",
    "    h = model.init_hidden(batch_size)\n",
    "    for inputs, labels in train_loader:\n",
    "        print('jjj===')\n",
    "        inputs, labels = inputs.to(device), labels.to(device)   \n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "        \n",
    "        model.zero_grad()\n",
    "        output,h = model(inputs,h)\n",
    "        \n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "        # calculating accuracy\n",
    "        accuracy = acc(output,labels)\n",
    "        train_acc += accuracy\n",
    "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    " \n",
    "    \n",
    "        \n",
    "    print('aaa')\n",
    "    val_h = model.init_hidden(batch_size)\n",
    "    val_losses = []\n",
    "    val_acc = 0.0\n",
    "    model.eval()\n",
    "    for inputs, labels in valid_loader:\n",
    "            print('ccc')\n",
    "            val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            output, val_h = model(inputs, val_h)\n",
    "            val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "            val_losses.append(val_loss.item())\n",
    "            \n",
    "            accuracy = acc(output,labels)\n",
    "            val_acc += accuracy\n",
    "            \n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_val_loss = np.mean(val_losses)\n",
    "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
    "    epoch_val_acc = val_acc/len(valid_loader.dataset)\n",
    "    epoch_tr_loss.append(epoch_train_loss)\n",
    "    epoch_vl_loss.append(epoch_val_loss)\n",
    "    epoch_tr_acc.append(epoch_train_acc)\n",
    "    epoch_vl_acc.append(epoch_val_acc)\n",
    "    print(f'Epoch {epoch+1}') \n",
    "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
    "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
    "    if epoch_val_loss <= valid_loss_min:\n",
    "        torch.save(model.state_dict(), '../working/state_dict.pt')\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
    "        valid_loss_min = epoch_val_loss\n",
    "    print(25*'==')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000aa289-ad3b-463f-a899-a1d6d5d3f2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
